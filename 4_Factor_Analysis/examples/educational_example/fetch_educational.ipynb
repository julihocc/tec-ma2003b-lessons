{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fetch_educational.py\n",
    "\n",
    "Minimal script to generate synthetic educational assessment data for PCA/FA comparison\n",
    "and save it as `educational.csv` in the same folder. This creates controlled\n",
    "educational assessment data with known underlying factor structure.\n",
    "\n",
    "Usage:\n",
    "    python fetch_educational.py\n",
    "\n",
    "Note: This generates synthetic but pedagogically useful data with known\n",
    "latent factors for method comparison.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a888b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eee8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Generate synthetic educational assessment data\"\"\"\n",
    "    dst = os.path.join(os.path.dirname(__file__), \"educational.csv\")\n",
    "\n",
    "    # Set random seed for reproducible data\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Number of students\n",
    "    n_students = 100\n",
    "\n",
    "    # Generate student IDs\n",
    "    student_ids = [f\"STUD_{i:03d}\" for i in range(1, n_students + 1)]\n",
    "\n",
    "    # Generate two orthogonal latent factors\n",
    "    intelligence_factor = np.random.normal(\n",
    "        size=(n_students, 1)\n",
    "    )  # Cognitive ability factor\n",
    "    personality_factor = np.random.normal(\n",
    "        size=(n_students, 1)\n",
    "    )  # Social/emotional factor\n",
    "\n",
    "    # Define noise terms for measurement error\n",
    "    measurement_noise_low = np.random.normal(\n",
    "        size=(n_students, 1)\n",
    "    )  # Low noise (σ = 0.2)\n",
    "    measurement_noise_med = np.random.normal(\n",
    "        size=(n_students, 1)\n",
    "    )  # Medium noise (σ = 0.25)\n",
    "    pure_noise_1 = np.random.normal(size=(n_students, 1))  # Pure noise variable 1\n",
    "    pure_noise_2 = np.random.normal(size=(n_students, 1))  # Pure noise variable 2\n",
    "\n",
    "    # Define factor loadings\n",
    "    strong_loading = 0.85  # Strong relationship to latent factor\n",
    "    moderate_loading = 0.80  # Moderate relationship to latent factor\n",
    "    low_noise_level = 0.2  # Low measurement error\n",
    "    med_noise_level = 0.25  # Medium measurement error\n",
    "    noise_variance_1 = 0.6  # Variance for first noise variable\n",
    "    noise_variance_2 = 0.5  # Variance for second noise variable\n",
    "\n",
    "    # Create observed variables with meaningful structure\n",
    "    math_test = (\n",
    "        strong_loading * intelligence_factor + low_noise_level * measurement_noise_low\n",
    "    )\n",
    "    verbal_test = (\n",
    "        moderate_loading * intelligence_factor + med_noise_level * measurement_noise_med\n",
    "    )\n",
    "    social_skills = (\n",
    "        strong_loading * personality_factor + low_noise_level * measurement_noise_low\n",
    "    )\n",
    "    leadership = (\n",
    "        moderate_loading * personality_factor + med_noise_level * measurement_noise_med\n",
    "    )\n",
    "    random_var1 = noise_variance_1 * pure_noise_1  # Pure noise (no latent structure)\n",
    "    random_var2 = noise_variance_2 * pure_noise_2  # Pure noise (no latent structure)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        \"Student\": student_ids,\n",
    "        \"MathTest\": np.round(math_test.flatten(), 2),\n",
    "        \"VerbalTest\": np.round(verbal_test.flatten(), 2),\n",
    "        \"SocialSkills\": np.round(social_skills.flatten(), 2),\n",
    "        \"Leadership\": np.round(leadership.flatten(), 2),\n",
    "        \"RandomVar1\": np.round(random_var1.flatten(), 2),\n",
    "        \"RandomVar2\": np.round(random_var2.flatten(), 2),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(dst, index=False)\n",
    "    print(f\"Generated {len(df)} student records\")\n",
    "    print(f\"Saved to {dst}\")\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(df.describe().round(2))\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ad1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    exit(main())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
