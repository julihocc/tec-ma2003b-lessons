{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fetch_invest.py\n",
    "\n",
    "Minimal script to generate synthetic European stock market data that closely\n",
    "resembles the EuStockMarkets dataset and save it as `invest.csv` in the same\n",
    "folder. Creates realistic time series with high correlations between indices.\n",
    "\n",
    "Usage:\n",
    "    python fetch_invest.py\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa59ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Generate synthetic European stock market indices data\"\"\"\n",
    "    dst = os.path.join(os.path.dirname(__file__), \"invest.csv\")\n",
    "\n",
    "    # Set random seed for reproducible data\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Parameters based on original EuStockMarkets data analysis\n",
    "    n_days = 1860  # Same number of observations as original\n",
    "\n",
    "    # Starting values (approximate means from original data)\n",
    "    start_values = {\"DAX\": 2500, \"SMI\": 3400, \"CAC\": 2200, \"FTSE\": 3600}\n",
    "\n",
    "    # Generate correlated random walks to simulate stock market behavior\n",
    "    # Create a common market factor that drives all indices\n",
    "    market_factor = np.random.normal(0, 0.01, n_days)  # Daily market returns\n",
    "\n",
    "    # Add some regional factors to create more realistic correlation structure\n",
    "    european_factor = np.random.normal(0, 0.008, n_days)  # European region factor\n",
    "    uk_factor = np.random.normal(0, 0.006, n_days)  # UK-specific factor\n",
    "\n",
    "    # Individual noise for each index (different volatilities to create varied correlations)\n",
    "    individual_noise = {\n",
    "        \"DAX\": np.random.normal(0, 0.008, n_days),\n",
    "        \"SMI\": np.random.normal(0, 0.006, n_days),  # SMI correlated but distinct\n",
    "        \"CAC\": np.random.normal(0, 0.010, n_days),  # CAC more independent\n",
    "        \"FTSE\": np.random.normal(0, 0.007, n_days),\n",
    "    }\n",
    "\n",
    "    # Weight of market factor vs individual noise (creates high but realistic correlation)\n",
    "    market_weight = 0.75  # Reduced from 0.85\n",
    "    individual_weight = 0.25  # Increased from 0.15\n",
    "\n",
    "    # Generate the time series\n",
    "    indices = {}\n",
    "    for index, start_val in start_values.items():\n",
    "        # Different factor loadings for each index to create varied correlations\n",
    "        if index == \"FTSE\":\n",
    "            # FTSE gets less European factor, more UK factor\n",
    "            returns = (\n",
    "                market_weight * market_factor\n",
    "                + 0.1 * european_factor\n",
    "                + 0.15 * uk_factor\n",
    "                + individual_weight * individual_noise[index]\n",
    "            )\n",
    "        elif index == \"CAC\":\n",
    "            # CAC gets more individual noise, less correlated\n",
    "            returns = (\n",
    "                0.65 * market_factor\n",
    "                + 0.2 * european_factor\n",
    "                + 0.15 * individual_noise[index]\n",
    "            )\n",
    "        else:\n",
    "            # DAX and SMI more European-focused\n",
    "            returns = (\n",
    "                market_weight * market_factor\n",
    "                + 0.15 * european_factor\n",
    "                + individual_weight * individual_noise[index]\n",
    "            )\n",
    "\n",
    "        # Convert returns to price levels using cumulative product\n",
    "        price_series = start_val * np.cumprod(1 + returns)\n",
    "        indices[index] = price_series\n",
    "\n",
    "    # Create DataFrame matching original structure\n",
    "    data = {\n",
    "        \"rownames\": range(1, n_days + 1),\n",
    "        \"DAX\": np.round(indices[\"DAX\"], 2),\n",
    "        \"SMI\": np.round(indices[\"SMI\"], 1),\n",
    "        \"CAC\": np.round(indices[\"CAC\"], 1),\n",
    "        \"FTSE\": np.round(indices[\"FTSE\"], 1),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    try:\n",
    "        df.to_csv(dst, index=False)\n",
    "        print(f\"Generated {len(df)} stock market observations\")\n",
    "        print(f\"Saved: {dst}\")\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        print(df.iloc[:, 1:].describe().round(1))\n",
    "\n",
    "        print(\"\\nCorrelation matrix:\")\n",
    "        print(df.iloc[:, 1:].corr().round(3))\n",
    "\n",
    "        return 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Write failed:\", e, file=sys.stderr)\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
